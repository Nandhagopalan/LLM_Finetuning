{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde7c93b909d4e8aa48f3c4a6be819dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1609c20cc204c0c817e0e4c82f938d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig\n",
    "from trl import setup_chat_format,ORPOConfig, ORPOTrainer\n",
    "from datasets import load_dataset\n",
    "import multiprocessing\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model  \n",
    "\n",
    "\n",
    "model_id=\"microsoft/phi-2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,    \n",
    "    device_map=\"auto\",\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "    ),\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # FA2 does not work yet\n",
    "    # attn_implementation=\"flash_attention_2\",          \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "\n",
    "# # set chat template to OAI chatML, remove if you start from a fine-tuned model\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "tokenizer.padding_side = 'right' # to prevent warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PreTrainedTokenizerBase.get_special_tokens_mask of CodeGenTokenizerFast(name_or_path='microsoft/phi-2', vocab_size=50257, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|im_start|>', 'eos_token': '<|im_end|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|im_end|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50257: AddedToken(\"                               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50258: AddedToken(\"                              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50259: AddedToken(\"                             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50260: AddedToken(\"                            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50261: AddedToken(\"                           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50262: AddedToken(\"                          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50263: AddedToken(\"                         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50264: AddedToken(\"                        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50265: AddedToken(\"                       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50266: AddedToken(\"                      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50267: AddedToken(\"                     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50268: AddedToken(\"                    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50269: AddedToken(\"                   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50270: AddedToken(\"                  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50271: AddedToken(\"                 \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50272: AddedToken(\"                \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50273: AddedToken(\"               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50274: AddedToken(\"              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50275: AddedToken(\"             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50276: AddedToken(\"            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50277: AddedToken(\"           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50278: AddedToken(\"          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50279: AddedToken(\"         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50280: AddedToken(\"        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50281: AddedToken(\"       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50282: AddedToken(\"      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50283: AddedToken(\"     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50284: AddedToken(\"    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50285: AddedToken(\"   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50286: AddedToken(\"  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50287: AddedToken(\"\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50288: AddedToken(\"\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50289: AddedToken(\"\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50290: AddedToken(\"\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50291: AddedToken(\"\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50292: AddedToken(\"\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50293: AddedToken(\"\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50294: AddedToken(\"\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50295: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50296: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_special_tokens_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True) \n",
    "\n",
    "# Adapter settings\n",
    "lora_config = LoraConfig(\n",
    "    r=32, \n",
    "    lora_alpha=32, \n",
    "    target_modules = [ \"q_proj\", \"k_proj\", \"v_proj\", \"dense\" ],\n",
    "    modules_to_save = [\"lm_head\", \"embed_tokens\"],\n",
    "    lora_dropout=0.1, \n",
    "    bias=\"none\", \n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the following config, we combine the usual HF Trainer args with the ORPOConfig args (beta)\n",
    "\n",
    "cfg = ORPOConfig(\n",
    "    output_dir='model/phi2-2b-orpo',     # usual HF Trainer args: https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer.args\n",
    "    num_train_epochs=3,                     # number of training epochs\n",
    "    per_device_train_batch_size=2,          # batch size per device during training\n",
    "    gradient_accumulation_steps=2,          # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
    "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
    "    logging_steps=20,                       # log every 20 steps\n",
    "    bf16=True,                              # use bfloat16 precision\n",
    "   # tf32=True,                              # use tf32          \n",
    "    learning_rate=5e-5,                     # learning rate\n",
    "    warmup_ratio=0.1,\n",
    "    warmup_steps=100,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_prompt_length=512,\n",
    "    remove_unused_columns=False,\n",
    "    max_length=1024,\n",
    "    beta=0.1,                               # ORPO beta\n",
    "    save_total_limit=3,                     # args related to saving the model...\n",
    "    save_strategy=\"epoch\",\n",
    "    push_to_hub=True,                   \n",
    "    hub_model_id='Nandhu/phi-2b-orpo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b71e58c90114f7887de8c7d98e8360e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/6750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79857636453d4bf4856f8a34b975e453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://github.com/huggingface/trl/blob/main/examples/scripts/orpo.py\n",
    "\n",
    "ds = load_dataset(\"alvarobartt/dpo-mix-7k-simplified\")\n",
    "\n",
    "def process(row):\n",
    "    row[\"prompt\"] = tokenizer.apply_chat_template(row[\"prompt\"], tokenize=False)\n",
    "    row[\"chosen\"] = tokenizer.apply_chat_template(row[\"chosen\"], tokenize=False)\n",
    "    row[\"rejected\"] = tokenizer.apply_chat_template(row[\"rejected\"], tokenize=False)\n",
    "    return row\n",
    "\n",
    "ds = ds.map(\n",
    "    process,\n",
    "    num_proc=multiprocessing.cpu_count(),\n",
    "    load_from_cache_file=False,\n",
    ")\n",
    "train_dataset = ds[\"train\"]\n",
    "eval_dataset = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dataset': 'argilla/distilabel-intel-orca-dpo-pairs',\n",
       "  'prompt': '<|im_start|>user\\nQ:Question: how old julio cesar chavez when he fought de la hoya I found the following answer on Google: He holds records for most successful consecutive defenses of world titles (27), most title fights (37), most title-fight victories (31) and he is after Joe Louis with (23) for most title defenses won by knockout (21). Is that a correct answer? Yes or no.\\nA:<|im_end|>\\n',\n",
       "  'chosen': \"<|im_start|>assistant\\n Yes, the information you found on Google is correct. Julio CÃ©sar ChÃ¡vez holds several records related to world title defenses and victories, and he is considered one of the greatest boxers in history. Here is a detailed answer to your question:\\n\\nJulio CÃ©sar ChÃ¡vez was born on July 12, 1962, in Ciudad ObregÃ³n, Sonora, Mexico. He began boxing at a young age and quickly made a name for himself in the sport, winning his first world title in 1984 when he defeated Mario Miranda for the WBC super featherweight championship.\\n\\nOver the course of his career, ChÃ¡vez would go on to hold titles in three different weight classes (super featherweight, lightweight, and junior welterweight) and defend his titles a record 27 times, including 21 times by knockout. This record for most successful consecutive defenses of world titles has never been broken, and it is a testament to ChÃ¡vez's skill, determination, and durability as a fighter.\\n\\nIn addition to his record for most successful title defenses, ChÃ¡vez also holds the records for most title fights (37) and most title-fight victories (31). These records are also unbroken and demonstrate ChÃ¡vez's consistent success and dominance in the ring.\\n\\nChÃ¡vez's impressive record and achievements have earned him a place among the greatest boxers of all time, and he is often compared to other boxing legends such as Joe Louis, who holds the record for most title defenses won by knockout (23). While ChÃ¡vez did not quite match Louis's record for most title defenses won by knockout, he is still widely regarded as one of the greatest boxers in history and a true legend of the sport.\\n\\nIn conclusion, the information you found on Google is correct: Julio CÃ©sar ChÃ¡vez holds several records related to world title defenses and victories, and he is considered one of the greatest boxers in history. His impressive record and achievements have earned him a place among the greatest boxers of all time, and he will always be remembered as a true legend of the sport.<|im_end|>\\n\",\n",
       "  'rejected': '<|im_start|>assistant\\nNo, the answer provided does not directly answer the question regarding the age of Julio Cesar Chavez when he fought Oscar De La Hoya. The provided information describes some general records held by Julio Cesar Chavez throughout his career. To answer your original question, let me provide the relevant information:\\n\\nJulio Cesar Chavez fought Oscar De La Hoya on June 7, 1996, in a match called \"Ultimate Glory.\" Chavez was born on July 12, 1962. To calculate his age at the time of the fight, we need to find the difference between the fight date and his birthdate.\\n\\nFrom July 12, 1962, to June 7, 1996, there are:\\n- 33 years (from 1962 to 1995)\\n- An additional year from his birthday in 1995 (July 12, 1995) to the fight date in 1996 (June 7, 1996), which is approximately 10 months and 26 days.\\n\\nTherefore, Julio Cesar Chavez was about 33 years and 10 months old when he fought Oscar De La Hoya.<|im_end|>\\n'},\n",
       " 6750)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0], len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpo_trainer = ORPOTrainer(\n",
    "    model=model,\n",
    "    args=cfg,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2dd7e3749c14765850bf0dc8fac09e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ijarvis/.cache/pypoetry/virtualenvs/llm-models-2lqcHvpG-py3.10/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.0773, 'grad_norm': 448.0132141113281, 'learning_rate': 1e-05, 'rewards/chosen': -0.19050651788711548, 'rewards/rejected': -0.2069549262523651, 'rewards/accuracies': 0.48750001192092896, 'rewards/margins': 0.01644841395318508, 'logps/rejected': -2.069549083709717, 'logps/chosen': -1.9050649404525757, 'logits/rejected': 0.9096983671188354, 'logits/chosen': 0.8772487640380859, 'nll_loss': 6.980725288391113, 'log_odds_ratio': -0.9662173986434937, 'log_odds_chosen': 0.16117547452449799, 'epoch': 0.01}\n",
      "{'loss': 6.7482, 'grad_norm': 725.6022338867188, 'learning_rate': 2e-05, 'rewards/chosen': -0.21175460517406464, 'rewards/rejected': -0.19826290011405945, 'rewards/accuracies': 0.4375, 'rewards/margins': -0.013491692952811718, 'logps/rejected': -1.9826290607452393, 'logps/chosen': -2.1175456047058105, 'logits/rejected': 0.9796890020370483, 'logits/chosen': 1.024097204208374, 'nll_loss': 6.6566033363342285, 'log_odds_ratio': -0.9162625074386597, 'log_odds_chosen': -0.1422257423400879, 'epoch': 0.02}\n",
      "{'loss': 5.653, 'grad_norm': 357.702392578125, 'learning_rate': 3e-05, 'rewards/chosen': -0.18895575404167175, 'rewards/rejected': -0.19046397507190704, 'rewards/accuracies': 0.5, 'rewards/margins': 0.001508189830929041, 'logps/rejected': -1.9046396017074585, 'logps/chosen': -1.8895576000213623, 'logits/rejected': 1.0119203329086304, 'logits/chosen': 1.0001741647720337, 'nll_loss': 5.563015937805176, 'log_odds_ratio': -0.899897575378418, 'log_odds_chosen': 0.006914444267749786, 'epoch': 0.04}\n",
      "{'loss': 4.1908, 'grad_norm': 137.1632537841797, 'learning_rate': 4e-05, 'rewards/chosen': -0.18250307440757751, 'rewards/rejected': -0.18970148265361786, 'rewards/accuracies': 0.512499988079071, 'rewards/margins': 0.007198411040008068, 'logps/rejected': -1.897014856338501, 'logps/chosen': -1.8250305652618408, 'logits/rejected': 0.7158540487289429, 'logits/chosen': 0.7326533794403076, 'nll_loss': 4.104490280151367, 'log_odds_ratio': -0.8632993698120117, 'log_odds_chosen': 0.0724111944437027, 'epoch': 0.05}\n",
      "{'loss': 2.1825, 'grad_norm': 20.653972625732422, 'learning_rate': 5e-05, 'rewards/chosen': -0.15711814165115356, 'rewards/rejected': -0.1640661209821701, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.006947965361177921, 'logps/rejected': -1.6406612396240234, 'logps/chosen': -1.5711815357208252, 'logits/rejected': -0.12043525278568268, 'logits/chosen': -0.14181077480316162, 'nll_loss': 2.1039652824401855, 'log_odds_ratio': -0.785670280456543, 'log_odds_chosen': 0.09216659516096115, 'epoch': 0.06}\n",
      "{'loss': 1.1889, 'grad_norm': 15.838240623474121, 'learning_rate': 4.999799494869234e-05, 'rewards/chosen': -0.14231230318546295, 'rewards/rejected': -0.15282189846038818, 'rewards/accuracies': 0.5874999761581421, 'rewards/margins': 0.010509609244763851, 'logps/rejected': -1.5282191038131714, 'logps/chosen': -1.4231230020523071, 'logits/rejected': -1.0282223224639893, 'logits/chosen': -1.056483507156372, 'nll_loss': 1.1166974306106567, 'log_odds_ratio': -0.7224633097648621, 'log_odds_chosen': 0.1370469033718109, 'epoch': 0.07}\n",
      "{'loss': 1.0739, 'grad_norm': 79.30198669433594, 'learning_rate': 4.999198011638779e-05, 'rewards/chosen': -0.12570378184318542, 'rewards/rejected': -0.13177916407585144, 'rewards/accuracies': 0.5, 'rewards/margins': 0.006075378507375717, 'logps/rejected': -1.3177915811538696, 'logps/chosen': -1.2570377588272095, 'logits/rejected': -1.469259262084961, 'logits/chosen': -1.4179049730300903, 'nll_loss': 0.9975967407226562, 'log_odds_ratio': -0.7628957629203796, 'log_odds_chosen': 0.07582198083400726, 'epoch': 0.08}\n",
      "{'loss': 1.0282, 'grad_norm': 16.100549697875977, 'learning_rate': 4.998195646789017e-05, 'rewards/chosen': -0.11594399064779282, 'rewards/rejected': -0.13740657269954681, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.0214625783264637, 'logps/rejected': -1.374065637588501, 'logps/chosen': -1.1594398021697998, 'logits/rejected': -1.3885236978530884, 'logits/chosen': -1.3925225734710693, 'nll_loss': 0.9611302614212036, 'log_odds_ratio': -0.6711433529853821, 'log_odds_chosen': 0.2717300057411194, 'epoch': 0.09}\n",
      "{'loss': 1.0635, 'grad_norm': 12.157066345214844, 'learning_rate': 4.996792561103383e-05, 'rewards/chosen': -0.12190566211938858, 'rewards/rejected': -0.12256760895252228, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.0006619381019845605, 'logps/rejected': -1.2256760597229004, 'logps/chosen': -1.2190566062927246, 'logits/rejected': -1.4687423706054688, 'logits/chosen': -1.4691394567489624, 'nll_loss': 0.9861211776733398, 'log_odds_ratio': -0.773750901222229, 'log_odds_chosen': 0.00871142465621233, 'epoch': 0.11}\n",
      "{'loss': 1.1321, 'grad_norm': 41.99684524536133, 'learning_rate': 4.994988979642579e-05, 'rewards/chosen': -0.12657524645328522, 'rewards/rejected': -0.13221454620361328, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.005639311857521534, 'logps/rejected': -1.3221454620361328, 'logps/chosen': -1.2657521963119507, 'logits/rejected': -1.571062445640564, 'logits/chosen': -1.6090328693389893, 'nll_loss': 1.058131456375122, 'log_odds_ratio': -0.7401601076126099, 'log_odds_chosen': 0.09693792462348938, 'epoch': 0.12}\n",
      "{'loss': 1.037, 'grad_norm': 7.826746940612793, 'learning_rate': 4.992785191708475e-05, 'rewards/chosen': -0.11879377067089081, 'rewards/rejected': -0.13443982601165771, 'rewards/accuracies': 0.612500011920929, 'rewards/margins': 0.01564604416489601, 'logps/rejected': -1.3443982601165771, 'logps/chosen': -1.1879377365112305, 'logits/rejected': -1.831964135169983, 'logits/chosen': -1.8176748752593994, 'nll_loss': 0.9694217443466187, 'log_odds_ratio': -0.675579845905304, 'log_odds_chosen': 0.20197634398937225, 'epoch': 0.13}\n",
      "{'loss': 1.0987, 'grad_norm': 8.579144477844238, 'learning_rate': 4.9901815507977034e-05, 'rewards/chosen': -0.11791630834341049, 'rewards/rejected': -0.12980352342128754, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.011887218803167343, 'logps/rejected': -1.2980351448059082, 'logps/chosen': -1.1791630983352661, 'logits/rejected': -1.6219587326049805, 'logits/chosen': -1.6683862209320068, 'nll_loss': 1.0281392335891724, 'log_odds_ratio': -0.7053070664405823, 'log_odds_chosen': 0.1520368903875351, 'epoch': 0.14}\n",
      "{'loss': 1.0938, 'grad_norm': 7.723580360412598, 'learning_rate': 4.98717847454495e-05, 'rewards/chosen': -0.1176743134856224, 'rewards/rejected': -0.12675312161445618, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.009078816510736942, 'logps/rejected': -1.267531156539917, 'logps/chosen': -1.1767429113388062, 'logits/rejected': -1.8827753067016602, 'logits/chosen': -1.826593041419983, 'nll_loss': 1.0194289684295654, 'log_odds_ratio': -0.7432175874710083, 'log_odds_chosen': 0.09171809256076813, 'epoch': 0.15}\n",
      "{'loss': 1.0777, 'grad_norm': 9.073094367980957, 'learning_rate': 4.983776444655974e-05, 'rewards/chosen': -0.11495228111743927, 'rewards/rejected': -0.1298120766878128, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.014859786257147789, 'logps/rejected': -1.2981207370758057, 'logps/chosen': -1.1495229005813599, 'logits/rejected': -1.5913091897964478, 'logits/chosen': -1.6886100769042969, 'nll_loss': 1.0076357126235962, 'log_odds_ratio': -0.7008274793624878, 'log_odds_chosen': 0.15536734461784363, 'epoch': 0.17}\n",
      "{'loss': 1.022, 'grad_norm': 9.61737060546875, 'learning_rate': 4.9799760068303335e-05, 'rewards/chosen': -0.11749899387359619, 'rewards/rejected': -0.1450417935848236, 'rewards/accuracies': 0.5874999761581421, 'rewards/margins': 0.027542805299162865, 'logps/rejected': -1.4504178762435913, 'logps/chosen': -1.1749898195266724, 'logits/rejected': -1.7234338521957397, 'logits/chosen': -1.826464056968689, 'nll_loss': 0.9577873945236206, 'log_odds_ratio': -0.6424871683120728, 'log_odds_chosen': 0.3374233841896057, 'epoch': 0.18}\n",
      "{'loss': 1.057, 'grad_norm': 8.926407814025879, 'learning_rate': 4.975777770673855e-05, 'rewards/chosen': -0.12212065607309341, 'rewards/rejected': -0.13512538373470306, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.01300473976880312, 'logps/rejected': -1.3512537479400635, 'logps/chosen': -1.2212064266204834, 'logits/rejected': -1.8418152332305908, 'logits/chosen': -1.8015985488891602, 'nll_loss': 0.9858220219612122, 'log_odds_ratio': -0.7116504311561584, 'log_odds_chosen': 0.1402779370546341, 'epoch': 0.19}\n",
      "{'loss': 1.0665, 'grad_norm': 16.095123291015625, 'learning_rate': 4.9711824096008494e-05, 'rewards/chosen': -0.1061234101653099, 'rewards/rejected': -0.11572001129388809, 'rewards/accuracies': 0.5, 'rewards/margins': 0.009596602991223335, 'logps/rejected': -1.1572000980377197, 'logps/chosen': -1.0612341165542603, 'logits/rejected': -1.913315773010254, 'logits/chosen': -1.872086524963379, 'nll_loss': 0.9969269037246704, 'log_odds_ratio': -0.6955993175506592, 'log_odds_chosen': 0.158134326338768, 'epoch': 0.2}\n",
      "{'loss': 1.1013, 'grad_norm': 4.752024173736572, 'learning_rate': 4.966190660726096e-05, 'rewards/chosen': -0.11394093185663223, 'rewards/rejected': -0.12219458818435669, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.008253666572272778, 'logps/rejected': -1.221945881843567, 'logps/chosen': -1.1394093036651611, 'logits/rejected': -1.9285526275634766, 'logits/chosen': -1.9525988101959229, 'nll_loss': 1.0281493663787842, 'log_odds_ratio': -0.7314622402191162, 'log_odds_chosen': 0.14154313504695892, 'epoch': 0.21}\n",
      "{'loss': 0.9709, 'grad_norm': 5.917745113372803, 'learning_rate': 4.960803324746603e-05, 'rewards/chosen': -0.10964439064264297, 'rewards/rejected': -0.13015660643577576, 'rewards/accuracies': 0.5874999761581421, 'rewards/margins': 0.020512204617261887, 'logps/rejected': -1.3015658855438232, 'logps/chosen': -1.0964438915252686, 'logits/rejected': -2.029299020767212, 'logits/chosen': -2.0398643016815186, 'nll_loss': 0.9055140614509583, 'log_odds_ratio': -0.6536521911621094, 'log_odds_chosen': 0.2840445637702942, 'epoch': 0.23}\n",
      "{'loss': 1.1532, 'grad_norm': 6.398833274841309, 'learning_rate': 4.9550212658131744e-05, 'rewards/chosen': -0.11618765443563461, 'rewards/rejected': -0.123285673558712, 'rewards/accuracies': 0.5874999761581421, 'rewards/margins': 0.007098034024238586, 'logps/rejected': -1.2328568696975708, 'logps/chosen': -1.1618764400482178, 'logits/rejected': -2.0998587608337402, 'logits/chosen': -2.052788496017456, 'nll_loss': 1.0798559188842773, 'log_odds_ratio': -0.7336757779121399, 'log_odds_chosen': 0.08661021292209625, 'epoch': 0.24}\n",
      "{'loss': 1.0691, 'grad_norm': 6.333268165588379, 'learning_rate': 4.948845411391796e-05, 'rewards/chosen': -0.11682579666376114, 'rewards/rejected': -0.12731915712356567, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.010493363253772259, 'logps/rejected': -1.2731914520263672, 'logps/chosen': -1.1682579517364502, 'logits/rejected': -2.0926852226257324, 'logits/chosen': -2.1167378425598145, 'nll_loss': 0.9957731366157532, 'log_odds_ratio': -0.7333705425262451, 'log_odds_chosen': 0.13310346007347107, 'epoch': 0.25}\n"
     ]
    }
   ],
   "source": [
    "orpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpo_trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### COMMENT IN TO MERGE PEFT AND BASE MODEL ####\n",
    "# from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "# # Load PEFT model on CPU\n",
    "# model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "#     \"model/phi2-2b-orpo\",\n",
    "#     torch_dtype=torch.float16,\n",
    "#     low_cpu_mem_usage=True,\n",
    "# )\n",
    "# # Merge LoRA and base model and save\n",
    "# merged_model = model.merge_and_unload()\n",
    "# merged_model.save_pretrained(\"model/phi2-2b-orpo\",safe_serialization=True, max_shard_size=\"2GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "modelpath=\"model/phi2-2b-orpo\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,    \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the meaning of life?\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": question},\n",
    "]\n",
    "        \n",
    "input_tokens = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "output_tokens = model.generate(input_tokens, max_new_tokens=200)\n",
    "output = tokenizer.decode(output_tokens[0])\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-models-2lqcHvpG-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
